{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fair-Classification Preferential Fairness Example\n",
    "\n",
    "Examples and explanations for function parameters https://github.com/mbilalzafar/fair-classification/tree/master/preferential_fairness."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import numpy as np\n",
    "sys.path.append(\"../\")\n",
    "\n",
    "from aif360.datasets import GermanDataset\n",
    "from aif360.metrics import ClassificationMetric\n",
    "from fairensics.data.synthetic_dataset import SyntheticDataset\n",
    "from fairensics.data.decision_boundary import DecisionBoundary \n",
    "from fairensics.methods import PreferentialFairness\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# helper function to print evaluations\n",
    "def print_evaluation(dataset, clf, unprivileged_groups, privileged_groups):\n",
    "    predictions = clf.predict(dataset)\n",
    "\n",
    "    metric = ClassificationMetric(dataset,\n",
    "                                  predictions,\n",
    "                                  unprivileged_groups=unprivileged_groups,\n",
    "                                  privileged_groups=privileged_groups)\n",
    "\n",
    "    print(\"p-rule: \\t\", metric.disparate_impact())\n",
    "    print('accuracy: \\t', metric.accuracy())\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 0.1 Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "gcd = GermanDataset()\n",
    "\n",
    "privileged_groups = [{'sex': 1}]\n",
    "unprivileged_groups = [{'sex': 0}]\n",
    "\n",
    "gcd_train, gcd_test = gcd.split([0.7], shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 0.2 Metric\n",
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0.2.1 Definition \n",
    "- $z$ the protected features\n",
    "- $X$ unprotected features\n",
    "- $\\hat{y}$ the predicted label\n",
    "- $\\hat{y}=1$ the positive label  (e.g. getting a loan)\n",
    "- $P_i(\\hat{y}=1)$ the probability for members of group _i_ to be assigned the positive label.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 0.2.2 Method\n",
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 0.3 Parameters\n",
    "**- loss_function [string]**\n",
    "- 'logreg' (default)\n",
    "- 'svm_linear\n",
    "- [logreg_2]\n",
    "\n",
    "**- constraint_type [string]**\n",
    "- None (default)\n",
    "- \"parity\"\n",
    "- \"impact\"\n",
    "- \"treatment\"\n",
    "- \"both\"\n",
    "\n",
    "**- lam [number]**\n",
    "- ...\n",
    "\n",
    "**-  s_val_to_cons_sum**\n",
    " - ...\n",
    "\n",
    "**- train_multiple [bool]**\n",
    " - if true, multiple classifiers are trained\n",
    "\n",
    "**- Solver Parameters**\n",
    "- tau\n",
    "- mu\n",
    "- EPS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PreferentialFairness without constraint\n",
      "p-rule: \t 0.9507027625839508\n",
      "accuracy: \t 0.7666666666666667\n"
     ]
    }
   ],
   "source": [
    "pref = PreferentialFairness(warn=False)\n",
    "print(\"PreferentialFairness without constraint\")\n",
    "pref.fit(gcd_train)\n",
    "print_evaluation(gcd_test, pref, unprivileged_groups, privileged_groups)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PreferentialFairness with parity constraint\n",
      "p-rule: \t 0.9712731836563938\n",
      "accuracy: \t 0.76\n"
     ]
    }
   ],
   "source": [
    "pref = PreferentialFairness(constraint_type=\"parity\", warn=False)\n",
    "print(\"PreferentialFairness with parity constraint\")\n",
    "pref.fit(gcd_train)\n",
    "print_evaluation(gcd_test, pref, unprivileged_groups, privileged_groups)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PreferentialFairness with treatment constraint\n",
      "p-rule: \t 0.7588306127910087\n",
      "accuracy: \t 0.7233333333333334\n"
     ]
    }
   ],
   "source": [
    "pref = PreferentialFairness(constraint_type=\"treatment\", train_multiple=True, warn=False)\n",
    "print(\"PreferentialFairness with treatment constraint\")\n",
    "pref.fit(gcd_train)\n",
    "\n",
    "print_evaluation(gcd_test, pref, unprivileged_groups, privileged_groups)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PreferentialFairness with impact constraint\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "../fairensics/methods/fairness_warnings.py:203: UserWarning: Ratio  between label and attribute  for protected attribute: protected_attribute is  above threshold of 0.4\n",
      "  warnings.warn(warning_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0.0: array([None], dtype=object), 1.0: array([None], dtype=object)}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "../fairensics/methods/preferential_fairness.py:244: UserWarning: Solver hasn't satisfied constraint. Make sure that the constraints are satisfied empirically. Alternatively, consider increasing tau parameter\n",
      "  warnings.warn(\"Solver hasn't satisfied constraint.\"\n"
     ]
    }
   ],
   "source": [
    "syn = SyntheticDataset()\n",
    "lam = {0:2.5, 1:0.01}\n",
    "\n",
    "pref = PreferentialFairness(constraint_type=\"impact\",  lam=lam, train_multiple=True, warn=False)\n",
    "print(\"PreferentialFairness with impact constraint\")\n",
    "pref.fit(syn)\n",
    "\n",
    "print(pref._params[\"w\"])\n",
    "\n",
    "#print_evaluation(gcd_test, pref, unprivileged_groups, privileged_groups)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "../fairensics/methods/fairness_warnings.py:203: UserWarning: Ratio  between label and attribute  for protected attribute: protected_attribute is  above threshold of 0.4\n",
      "  warnings.warn(warning_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PreferentialFairness with both constraints\n",
      "[None]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "../fairensics/methods/preferential_fairness.py:244: UserWarning: Solver hasn't satisfied constraint. Make sure that the constraints are satisfied empirically. Alternatively, consider increasing tau parameter\n",
      "  warnings.warn(\"Solver hasn't satisfied constraint.\"\n"
     ]
    }
   ],
   "source": [
    "pref = PreferentialFairness(constraint_type=\"both\", lam=lam, train_multiple=True, warn=False)\n",
    "print(\"PreferentialFairness with both constraints\")\n",
    "pref.fit(syn)\n",
    "\n",
    "print(pref._params[\"w\"][0])\n",
    "\n",
    "#print_evaluation(gcd_test, pref, unprivileged_groups, privileged_groups)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
