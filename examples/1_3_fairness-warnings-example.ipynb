{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fairness Warnings Example\n",
    "When fair-classification methods are called, warnings related to fairness violations may be raised.\n",
    "The goal of the two fairness warnings classes is, to provide easy access to methods to check data sets and classifiers for imbalances.  \n",
    "\n",
    "Two types of warning can be raised, based on either the data set being skewed or the classifier missing some boundary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from aif360.datasets import BinaryLabelDataset\n",
    "sys.path.append(\"../\")\n",
    " \n",
    "from fairensics.methods import FairDisparateImpact, AccurateDisparateImpact\n",
    "from fairensics.methods.fairness_warnings import FairnessBoundsWarning, DataSetSkewedWarning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# helper function to generate skewed data sets\n",
    "def to_aif_dataset(X, X_protected, y):\n",
    "\n",
    "    d = {\"age\": X_protected, \"label\": y}\n",
    "    for i in range(np.shape(X)[1]):\n",
    "        d[\"feature_\"+str(i)] = X[:, i]\n",
    "        \n",
    "    df = pd.DataFrame(data=d)\n",
    "    \n",
    "    aif_df = BinaryLabelDataset(df=df, \n",
    "                                label_names=[\"label\"], \n",
    "                                protected_attribute_names=[\"age\"])\n",
    "    return aif_df    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Data Set Warnings\n",
    "Data set warnings should be executed before the classifiers ``fit`` method is called. The warnings are implemented in the class ``DatasetSkewedWarning`` and are executed by calling the ``check_dataset`` method. Global attributes of the class store the warning thresholds. If a threshold is ``None`` the warning is ignored.\n",
    "\n",
    "Three different types of skewness are distinguished:\n",
    "- label skewness (unbalanced ration of different label classes)\n",
    "- attribute class skewness (unbalanced ration of protected attribute classes)\n",
    "- label and attribute class skewness (unbalanced ration for each combination of protected attribute and label class)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1 Skewed Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a data set with skewed labels\n",
    "n_samples = 100\n",
    "n_pos_label = 10\n",
    "\n",
    "X = np.random.rand(n_samples, 3)\n",
    "X_protected = np.random.randint(0, 2, size=n_samples)\n",
    "y = np.hstack((np.ones(n_pos_label), \n",
    "               np.zeros(n_samples-n_pos_label)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "../fairensics/methods/fairness_warnings.py:194: UserWarning: Ratio between labels is above tolerated ratio of 0.4\n",
      "  warnings.warn(warning_msg)\n",
      "../fairensics/methods/fairness_warnings.py:203: UserWarning: Ratio  between label and attribute  for protected attribute: age is  above threshold of 0.4\n",
      "  warnings.warn(warning_msg)\n"
     ]
    }
   ],
   "source": [
    "skew_labels = to_aif_dataset(X, X_protected, y)\n",
    "data_warning = DataSetSkewedWarning(skew_labels)\n",
    "data_warning.check_dataset()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 Unbalanced Protected Attribute Classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a data set with unbalanced class count\n",
    "n_samples = 100\n",
    "n_pos_label = 10\n",
    "\n",
    "X = np.random.rand(n_samples, 3)\n",
    "X_protected = np.hstack((np.ones(n_pos_label), np.zeros(n_samples-n_pos_label)))\n",
    "y = np.random.randint(0, 2, size=n_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "../fairensics/methods/fairness_warnings.py:203: UserWarning: Ratio  between groups  for protected attribute: age is  above threshold of 0.4\n",
      "  warnings.warn(warning_msg)\n",
      "../fairensics/methods/fairness_warnings.py:203: UserWarning: Ratio  between label and attribute  for protected attribute: age is  above threshold of 0.4\n",
      "  warnings.warn(warning_msg)\n"
     ]
    }
   ],
   "source": [
    "skew_prot_attr = to_aif_dataset(X, X_protected, y)\n",
    "data_warning = DataSetSkewedWarning(skew_prot_attr)\n",
    "data_warning.check_dataset()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.3 Unbalanced Combination of Protected Attribute and Label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a data set with skewed labels\n",
    "n_samples = 100\n",
    "n_pos_label = 10\n",
    "\n",
    "X = np.random.rand(n_samples, 3)\n",
    "X_protected = np.hstack((np.ones(n_pos_label), np.zeros(n_samples-n_pos_label)))\n",
    "y = np.random.randint(0, 2, size=n_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "../fairensics/methods/fairness_warnings.py:203: UserWarning: Ratio  between groups  for protected attribute: age is  above threshold of 0.4\n",
      "  warnings.warn(warning_msg)\n",
      "../fairensics/methods/fairness_warnings.py:203: UserWarning: Ratio  between label and attribute  for protected attribute: age is  above threshold of 0.4\n",
      "  warnings.warn(warning_msg)\n"
     ]
    }
   ],
   "source": [
    "skew_prot_attr = to_aif_dataset(X, X_protected, y)\n",
    "data_warning = DataSetSkewedWarning(skew_prot_attr)\n",
    "data_warning.check_dataset()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.4 Redefining the Default Bounds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "../fairensics/methods/fairness_warnings.py:203: UserWarning: Ratio  between groups  for protected attribute: age is  above threshold of 0.1\n",
      "  warnings.warn(warning_msg)\n",
      "../fairensics/methods/fairness_warnings.py:203: UserWarning: Ratio  between label and attribute  for protected attribute: age is  above threshold of 0.05\n",
      "  warnings.warn(warning_msg)\n"
     ]
    }
   ],
   "source": [
    "data_warning = DataSetSkewedWarning(skew_prot_attr)\n",
    "\n",
    "data_warning.POSITIVE_NEGATIVE_CLASS_FRACTION = .1 # default is.4\n",
    "data_warning.POSITIVE_NEGATIVE_LABEL_FRACTION = .2 # default is .4\n",
    "data_warning.CLASS_LABEL_FRACTION = .05 # default is .4\n",
    "data_warning.check_dataset()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Classifier Warnings\n",
    "Classifier warnings are executed after the classifier is trained. Again, thresholds are stored in global variables of the class and checks are only executed if a bound is not ``None``.\n",
    "\n",
    "Both thresholds for ratios and differences can be provided."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1 Using Default Bounds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_samples = 100\n",
    "n_pos_label = 10\n",
    "\n",
    "X = np.random.rand(n_samples, 3)\n",
    "X_protected = np.hstack((np.ones(n_pos_label), np.zeros(n_samples-n_pos_label)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# defining predictions\n",
    "y = np.random.randint(0, 2, size=n_samples)\n",
    "\n",
    "predicted_dataset = to_aif_dataset(X, X_protected, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# raw data set \n",
    "y_new = np.random.randint(0, 2, size=n_samples)\n",
    "\n",
    "raw_dataset = to_aif_dataset(X, X_protected, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "../fairensics/methods/fairness_warnings.py:203: UserWarning: Ratio  between groups  for protected attribute: age is  above threshold of 0.1\n",
      "  warnings.warn(warning_msg)\n",
      "../fairensics/methods/fairness_warnings.py:203: UserWarning: Ratio  between label and attribute  for protected attribute: age is  above threshold of 0.05\n",
      "  warnings.warn(warning_msg)\n"
     ]
    }
   ],
   "source": [
    "clf_warning = FairnessBoundsWarning(raw_dataset, predicted_dataset)\n",
    "data_warning.check_dataset()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 Defining New Bounds\n",
    "If a Bound is set to ``None`` the metric is not checked."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "../fairensics/methods/fairness_warnings.py:203: UserWarning: Ratio  between groups  for protected attribute: age is  above threshold of 0.1\n",
      "  warnings.warn(warning_msg)\n",
      "../fairensics/methods/fairness_warnings.py:203: UserWarning: Ratio  between label and attribute  for protected attribute: age is  above threshold of 0.05\n",
      "  warnings.warn(warning_msg)\n"
     ]
    }
   ],
   "source": [
    "clf_warning = FairnessBoundsWarning(raw_dataset, predicted_dataset)\n",
    "\n",
    "clf_warning.DISPARATE_IMPACT_RATIO_BOUND = None # default is .8\n",
    "clf_warning.FPR_RATIO_BOUND = None # default is .8\n",
    "clf_warning.FNR_RATIO_BOUND = None # default is .8\n",
    "clf_warning.ERROR_RATIO_BOUND = None # default is .8\n",
    "\n",
    "clf_warning.EO_DIFFERENCE_BOUND = .2 # default is .1\n",
    "\n",
    "clf_warning.FPR_DIFFERENCE_BOUND = None # default is None\n",
    "clf_warning.FNR_DIFFERENCE_BOUND = None # None default is None\n",
    "clf_warning.ERROR_DIFFERENCE_BOUND = .3 # default is None\n",
    "\n",
    "data_warning.check_dataset()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
