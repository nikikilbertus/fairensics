{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Disparate Impact Remover Example\n",
    "Examples and explanations for function parameters https://github.com/mbilalzafar/fair-classification/tree/master/disparate_impact."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import numpy as np\n",
    "sys.path.append(\"../\")\n",
    "\n",
    "from aif360.datasets import GermanDataset\n",
    "from aif360.metrics import ClassificationMetric\n",
    "from fairensics.data.synthetic_dataset import SyntheticDataset\n",
    "from fairensics.data.decision_boundary import DecisionBoundary \n",
    "from fairensics.methods import FairDisparateImpact, AccurateDisparateImpact\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# helper function to print evaluations\n",
    "def print_evaluation(dataset, clf, unprivileged_groups, privileged_groups):\n",
    "    predictions = clf.predict(dataset)\n",
    "\n",
    "    metric = ClassificationMetric(dataset,\n",
    "                                  predictions,\n",
    "                                  unprivileged_groups=unprivileged_groups,\n",
    "                                  privileged_groups=privileged_groups)\n",
    "\n",
    "    print(\"p-rule: \\t\", metric.disparate_impact())\n",
    "    print('accuracy: \\t', metric.accuracy())\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 0.1 Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "gcd = GermanDataset()\n",
    "\n",
    "privileged_groups = [{'sex': 1}]\n",
    "unprivileged_groups = [{'sex': 0}]\n",
    "\n",
    "gcd_train, gcd_test = gcd.split([0.7], shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 0.2  Metric\n",
    "\n",
    "- _disparate impact / p-rule_\n",
    "\n",
    "The acceptance rate must be equal for all groups, independent of the true outcome:\n",
    "\n",
    "$$P_1(\\hat{y}=1)=P_2(\\hat{y}=1)$$\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0.2.1 Definition \n",
    "- $z$ the protected features\n",
    "- $X$ unprotected features\n",
    "- $\\hat{y}$ the predicted label\n",
    "- $\\hat{y}=1$ the positive label  (e.g. getting a loan)\n",
    "- $P_i(\\hat{y}=1)$ the probability for members of group _i_ to be assigned the positive label.\n",
    "\n",
    "The p-rule is a relaxation of disparate impact:\n",
    "\n",
    "- _p-rule_ definition: $$\\frac{P_i(\\hat{y}=1)}{P_j(\\hat{y}=1)} \\geq p$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0.2.2 Method\n",
    "To satisfy the p-rule, the covariance between decision boundary and protected attributes is minimized:\n",
    "\n",
    "$$cov(d(x), z) = \\mathbb{E}[(z-\\bar{z})d(x)] \\cdot \\mathbb{E}[((z-\\bar{z})\\hat{d}(x))) ] \\approx \\frac{1}{N} \\sum _i ^N (z_i - \\bar{z})d(x_i)$$\n",
    "\n",
    "\n",
    "Either by optimizing for accuracy under p-rule constraints or by optimizing for fairness under accuracy constraints.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 0.3 Parameters (for both constraints)\n",
    "\n",
    "**- loss function [string]**\n",
    "- 'logreg' (default)\n",
    "- 'logreg_l2 \n",
    "- 'svm_linear'\n",
    "\n",
    "**- sensitive_attributes [list]**\n",
    "- list of sensitive attributes to apply constraints to, if not given constraints are aplied to all attributes\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Optimizing  for Accuracy Subject to Fairness Constraints\n",
    " _c_: the covariance threshold that can be passed to the function\n",
    "\n",
    "***minimize***\n",
    "$$L(\\theta)$$\n",
    "***subject to***\n",
    "$$\\frac{1}{N} \\sum _i ^N (z_i - \\bar{z})d_\\theta(x_i) \\leq c$$\n",
    "$$\\frac{1}{N} \\sum _i ^N (z_i - \\bar{z})d_\\theta(x_i) \\geq -c$$\n",
    "\n",
    "# 1.1 Parameters\n",
    "\n",
    "**- sensitive_attrs_to_cov_thresh** [dictionary]\n",
    "- the _c_ in above equation, covariance threshold for each sensitive attribute _{'attribute1_name':tresh_1, ...}_    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DisparateImpact with fairness constraint:\n",
      "p-rule: \t 1.0657904187315952\n",
      "accuracy: \t 0.7166666666666667\n"
     ]
    }
   ],
   "source": [
    "dspim = AccurateDisparateImpact(warn=False)\n",
    "print(\"DisparateImpact with fairness constraint:\")\n",
    "dspim.fit(gcd_train)\n",
    "print_evaluation(gcd_test, dspim, unprivileged_groups, privileged_groups)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Optimizing Fairness Subject to Accuracy\n",
    "$\\gamma$ must be passed when optimizing for fairness and $L(\\theta ^*)$ is the loss of the unconstrained classifier computed automatically\n",
    "\n",
    "minimize\n",
    "$$\\frac{1}{N} \\sum _i ^N (z_i - \\bar{z})d_\\theta(x_i)$$\n",
    "subject to\n",
    "$$L(\\theta) \\leq (1-\\gamma)L(\\theta ^*)$$\n",
    "\n",
    "## 2.1 Parameters\n",
    "\n",
    "**- gamma [number]**\n",
    "- tradeoff between accuracy and fairness when optimizing for fairness\n",
    "\n",
    "**- sep_constraint [bool]**\n",
    "- fine grained accuracy constraint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DisparateImpact with accuracy constraint:\n",
      "p-rule: \t 1.0173316616269636\n",
      "accuracy: \t 0.7266666666666667\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "../fairensics/methods/disparate_impact.py:364: UserWarning: Only the first protected attribute is considered with this constraint.\n",
      "  warnings.warn(\"Only the first protected attribute is considered with this constraint.\")\n"
     ]
    }
   ],
   "source": [
    "dspim = FairDisparateImpact(warn=False)\n",
    "print(\"DisparateImpact with accuracy constraint:\")\n",
    "dspim.fit(gcd_train)\n",
    "print_evaluation(gcd_test, dspim, unprivileged_groups, privileged_groups)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
